{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e7c4f2b7",
   "metadata": {},
   "source": [
    "#Model Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0e2a759a",
   "metadata": {
    "id": "0e2a759a"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler, LabelEncoder\n",
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.ensemble import ExtraTreesClassifier\n",
    "from matplotlib import pyplot as plt\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "import tensorflow as tf\n",
    "from imblearn.ensemble import BalancedRandomForestClassifier\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "from sklearn.metrics import balanced_accuracy_score\n",
    "from sklearn import tree\n",
    "from numpy import mean\n",
    "from sklearn.datasets import make_classification\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import RepeatedStratifiedKFold\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from imblearn.pipeline import Pipeline\n",
    "from imblearn.over_sampling import RandomOverSampler\n",
    "from imblearn.under_sampling import RandomUnderSampler \n",
    "from imblearn.ensemble import BalancedRandomForestClassifier, RUSBoostClassifier, BalancedBaggingClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from imblearn.metrics import classification_report_imbalanced\n",
    "from imblearn.combine import SMOTEENN\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8edc953b",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 419
    },
    "id": "8edc953b",
    "outputId": "0007315c-7039-4b8f-ead5-280390eab19a",
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>gender</th>\n",
       "      <th>age</th>\n",
       "      <th>hypertension</th>\n",
       "      <th>heart_disease</th>\n",
       "      <th>ever_married</th>\n",
       "      <th>work_type</th>\n",
       "      <th>residence_type</th>\n",
       "      <th>avg_glucose_level</th>\n",
       "      <th>bmi</th>\n",
       "      <th>smoking_status</th>\n",
       "      <th>stroke</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>26.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>78.05</td>\n",
       "      <td>30.8</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>71.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>108.70</td>\n",
       "      <td>31.2</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>46.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>201.42</td>\n",
       "      <td>50.8</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>52.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>124.27</td>\n",
       "      <td>22.2</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>67.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>95.48</td>\n",
       "      <td>30.1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29060</th>\n",
       "      <td>0</td>\n",
       "      <td>51.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>226.04</td>\n",
       "      <td>27.1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29061</th>\n",
       "      <td>0</td>\n",
       "      <td>60.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>71.98</td>\n",
       "      <td>33.4</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29062</th>\n",
       "      <td>0</td>\n",
       "      <td>45.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>77.45</td>\n",
       "      <td>42.2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29063</th>\n",
       "      <td>1</td>\n",
       "      <td>21.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>88.31</td>\n",
       "      <td>46.6</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29064</th>\n",
       "      <td>0</td>\n",
       "      <td>75.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>56.23</td>\n",
       "      <td>25.3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>29065 rows Ã— 11 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       gender   age  hypertension  heart_disease  ever_married  work_type  \\\n",
       "0           0  26.0             0              0             0          2   \n",
       "1           1  71.0             1              0             1          2   \n",
       "2           0  46.0             0              0             1          2   \n",
       "3           0  52.0             0              0             1          2   \n",
       "4           1  67.0             0              0             1          2   \n",
       "...       ...   ...           ...            ...           ...        ...   \n",
       "29060       0  51.0             0              0             1          0   \n",
       "29061       0  60.0             0              0             1          2   \n",
       "29062       0  45.0             0              0             0          0   \n",
       "29063       1  21.0             0              0             1          2   \n",
       "29064       0  75.0             0              0             1          0   \n",
       "\n",
       "       residence_type  avg_glucose_level   bmi  smoking_status  stroke  \n",
       "0                   0              78.05  30.8               1       0  \n",
       "1                   1             108.70  31.2               2       0  \n",
       "2                   1             201.42  50.8               2       0  \n",
       "3                   0             124.27  22.2               2       0  \n",
       "4                   0              95.48  30.1               0       0  \n",
       "...               ...                ...   ...             ...     ...  \n",
       "29060               1             226.04  27.1               1       0  \n",
       "29061               0              71.98  33.4               1       0  \n",
       "29062               0              77.45  42.2               0       0  \n",
       "29063               0              88.31  46.6               1       0  \n",
       "29064               0              56.23  25.3               1       0  \n",
       "\n",
       "[29065 rows x 11 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('Resources/model_clean_data.csv')\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "L-8WRDGv8rjd",
   "metadata": {
    "id": "L-8WRDGv8rjd"
   },
   "outputs": [],
   "source": [
    "# Randomize the data frame\n",
    "df = df.sample(frac=1).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "cadbd772",
   "metadata": {
    "id": "cadbd772"
   },
   "outputs": [],
   "source": [
    "#Divide the target column and the features column\n",
    "y = df['stroke']\n",
    "X = df.drop(['stroke'], axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e98b8703",
   "metadata": {
    "id": "e98b8703"
   },
   "outputs": [],
   "source": [
    "# Split the data in training and testing using sklearn\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, train_size=.85, random_state=12)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "12b05429",
   "metadata": {
    "id": "12b05429"
   },
   "outputs": [],
   "source": [
    "#Scale the data using StandardScaler\n",
    "scaler = StandardScaler().fit(X_train)\n",
    "X_train_scaled = scaler.transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "i0HNs8t3Vu5r",
   "metadata": {
    "id": "i0HNs8t3Vu5r"
   },
   "outputs": [],
   "source": [
    "#Scale the data using MinMaxScaler\n",
    "scaler = MinMaxScaler().fit(X_train)\n",
    "X_train_mscaled = scaler.transform(X_train)\n",
    "X_test_mscaled = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "42ed42af",
   "metadata": {
    "id": "42ed42af"
   },
   "outputs": [],
   "source": [
    "#Define test_model function that will test multiple smoteenn models.\n",
    "\n",
    "def test_model_smot(model, data):\n",
    "    X_train_smot, X_test_smot, y_train_smot, y_test_smot = data\n",
    "    reg = model.fit(X_train_smot, y_train_smot)\n",
    "    \n",
    "    print(f'Model: {type(reg).__name__}')\n",
    "    print(f'Train score: {reg.score(X_train_smot, y_train_smot)}')\n",
    "    print(f'Test Score: {reg.score(X_test, y_test)}\\n')\n",
    "    y_pred = reg.predict(X_test)\n",
    "    y_true = y_test\n",
    "    print(confusion_matrix(y_true, y_pred))\n",
    "    print(classification_report(y_true, y_pred))\n",
    "    print('----------------------------------------------------------------')\n",
    "    print(classification_report_imbalanced(y_true, y_pred))\n",
    "    print(f'Balanced Accuracy: {balanced_accuracy_score(y_true, y_pred)}')\n",
    "    print('----------------------------------------------------------------')\n",
    "       "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "mnfMlLCKXGA8",
   "metadata": {
    "id": "mnfMlLCKXGA8"
   },
   "outputs": [],
   "source": [
    "#Define test_model function that will test multiple oversampled models.\n",
    "\n",
    "def test_model_over(model, data):\n",
    "    oversample = RandomOverSampler(sampling_strategy=0.5)\n",
    "    X_over, y_over = oversample.fit_resample(X_train_scaled, y_train)\n",
    "    data = X_over, X_test_scaled, y_over, y_test\n",
    "    reg = model.fit(X_over, y_over)\n",
    "    \n",
    "    print(f'Model: {type(reg).__name__}')\n",
    "    print(f'Train score: {reg.score(X_train_scaled, y_train)}')\n",
    "    print(f'Test Score: {reg.score(X_test_scaled, y_test)}\\n')\n",
    "    y_pred = reg.predict(X_test_scaled)\n",
    "    y_true = y_test\n",
    "    print(confusion_matrix(y_true, y_pred))\n",
    "    print(classification_report(y_test, y_pred))\n",
    "    print(f'Balanced Accuracy: {balanced_accuracy_score(y_test, y_pred)}')\n",
    "    print('----------------------------------------------------------------')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "vH0YBujRWxNR",
   "metadata": {
    "id": "vH0YBujRWxNR"
   },
   "outputs": [],
   "source": [
    "#Define test_model function that will test multiple oversampled models.\n",
    "\n",
    "def test_model_under(model, data):\n",
    "    undersample = RandomUnderSampler(sampling_strategy=0.5)\n",
    "    X_under, y_under = undersample.fit_resample(X_train_scaled, y_train)\n",
    "    data = X_under, X_test_scaled, y_under, y_test\n",
    "    reg = model.fit(X_under, y_under)\n",
    "\n",
    "    print(f'Model: {type(reg).__name__}')\n",
    "    print(f'Train score: {reg.score(X_train_scaled, y_train)}')\n",
    "    print(f'Test Score: {reg.score(X_test_scaled, y_test)}\\n')\n",
    "    y_pred = reg.predict(X_test_scaled)\n",
    "    y_true = y_test\n",
    "    print(confusion_matrix(y_true, y_pred))\n",
    "    print(classification_report(y_test, y_pred))\n",
    "    print(f'Balanced Accuracy: {balanced_accuracy_score(y_test, y_pred)}')\n",
    "    print('----------------------------------------------------------------')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "77679c4b",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "77679c4b",
    "outputId": "02d7cf49-ad44-42a8-9a03-6c488b9a5b3e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: LogisticRegression\n",
      "Train score: 0.8395871281117183\n",
      "Test Score: 0.846788990825688\n",
      "\n",
      "[[3635  632]\n",
      " [  36   57]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.85      0.92      4267\n",
      "           1       0.08      0.61      0.15        93\n",
      "\n",
      "    accuracy                           0.85      4360\n",
      "   macro avg       0.54      0.73      0.53      4360\n",
      "weighted avg       0.97      0.85      0.90      4360\n",
      "\n",
      "Balanced Accuracy: 0.7323948985840321\n",
      "----------------------------------------------------------------\n",
      "Model: GaussianNB\n",
      "Train score: 0.8216555353167375\n",
      "Test Score: 0.8247706422018348\n",
      "\n",
      "[[3548  719]\n",
      " [  45   48]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.83      0.90      4267\n",
      "           1       0.06      0.52      0.11        93\n",
      "\n",
      "    accuracy                           0.82      4360\n",
      "   macro avg       0.53      0.67      0.51      4360\n",
      "weighted avg       0.97      0.82      0.89      4360\n",
      "\n",
      "Balanced Accuracy: 0.6738132857564051\n",
      "----------------------------------------------------------------\n",
      "Model: KNeighborsClassifier\n",
      "Train score: 0.9673345476624166\n",
      "Test Score: 0.9337155963302752\n",
      "\n",
      "[[4059  208]\n",
      " [  81   12]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.95      0.97      4267\n",
      "           1       0.05      0.13      0.08        93\n",
      "\n",
      "    accuracy                           0.93      4360\n",
      "   macro avg       0.52      0.54      0.52      4360\n",
      "weighted avg       0.96      0.93      0.95      4360\n",
      "\n",
      "Balanced Accuracy: 0.5401430331803715\n",
      "----------------------------------------------------------------\n",
      "Model: AdaBoostClassifier\n",
      "Train score: 0.8490993725966404\n",
      "Test Score: 0.8573394495412844\n",
      "\n",
      "[[3683  584]\n",
      " [  38   55]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.86      0.92      4267\n",
      "           1       0.09      0.59      0.15        93\n",
      "\n",
      "    accuracy                           0.86      4360\n",
      "   macro avg       0.54      0.73      0.54      4360\n",
      "weighted avg       0.97      0.86      0.91      4360\n",
      "\n",
      "Balanced Accuracy: 0.7272667709931936\n",
      "----------------------------------------------------------------\n",
      "Model: SVC\n",
      "Train score: 0.8771503744181339\n",
      "Test Score: 0.8694954128440368\n",
      "\n",
      "[[3753  514]\n",
      " [  55   38]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.88      0.93      4267\n",
      "           1       0.07      0.41      0.12        93\n",
      "\n",
      "    accuracy                           0.87      4360\n",
      "   macro avg       0.53      0.64      0.52      4360\n",
      "weighted avg       0.97      0.87      0.91      4360\n",
      "\n",
      "Balanced Accuracy: 0.6440714057117514\n",
      "----------------------------------------------------------------\n",
      "Model: RandomForestClassifier\n",
      "Train score: 1.0\n",
      "Test Score: 0.9777522935779817\n",
      "\n",
      "[[4263    4]\n",
      " [  93    0]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      1.00      0.99      4267\n",
      "           1       0.00      0.00      0.00        93\n",
      "\n",
      "    accuracy                           0.98      4360\n",
      "   macro avg       0.49      0.50      0.49      4360\n",
      "weighted avg       0.96      0.98      0.97      4360\n",
      "\n",
      "Balanced Accuracy: 0.49953128661823293\n",
      "----------------------------------------------------------------\n",
      "Model: ExtraTreesClassifier\n",
      "Train score: 1.0\n",
      "Test Score: 0.9772935779816514\n",
      "\n",
      "[[4261    6]\n",
      " [  93    0]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      1.00      0.99      4267\n",
      "           1       0.00      0.00      0.00        93\n",
      "\n",
      "    accuracy                           0.98      4360\n",
      "   macro avg       0.49      0.50      0.49      4360\n",
      "weighted avg       0.96      0.98      0.97      4360\n",
      "\n",
      "Balanced Accuracy: 0.4992969299273494\n",
      "----------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "# Test oversampled\n",
    "oversample = RandomOverSampler(sampling_strategy=0.5)\n",
    "X_over, y_over = oversample.fit_resample(X_train_scaled, y_train)\n",
    "data = X_over, X_test_scaled, y_over, y_test\n",
    "\n",
    "\n",
    "test_model_over(LogisticRegression(), data)\n",
    "test_model_over(GaussianNB(), data)\n",
    "test_model_over(KNeighborsClassifier(), data)\n",
    "test_model_over(AdaBoostClassifier(), data)\n",
    "test_model_over(SVC(), data)\n",
    "test_model_over(RandomForestClassifier(), data)\n",
    "test_model_over(ExtraTreesClassifier(), data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "fhpZ2Dq-lOaO",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "fhpZ2Dq-lOaO",
    "outputId": "21863261-9b26-4be5-e72b-db6d9b64bb40"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: LogisticRegression\n",
      "Train score: 0.8397895162922485\n",
      "Test Score: 0.8483944954128441\n",
      "\n",
      "[[3640  627]\n",
      " [  34   59]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.85      0.92      4267\n",
      "           1       0.09      0.63      0.15        93\n",
      "\n",
      "    accuracy                           0.85      4360\n",
      "   macro avg       0.54      0.74      0.53      4360\n",
      "weighted avg       0.97      0.85      0.90      4360\n",
      "\n",
      "Balanced Accuracy: 0.7437334784832839\n",
      "----------------------------------------------------------------\n",
      "Model: GaussianNB\n",
      "Train score: 0.8252580449301761\n",
      "Test Score: 0.828440366972477\n",
      "\n",
      "[[3565  702]\n",
      " [  46   47]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.84      0.91      4267\n",
      "           1       0.06      0.51      0.11        93\n",
      "\n",
      "    accuracy                           0.83      4360\n",
      "   macro avg       0.53      0.67      0.51      4360\n",
      "weighted avg       0.97      0.83      0.89      4360\n",
      "\n",
      "Balanced Accuracy: 0.6704289735428935\n",
      "----------------------------------------------------------------\n",
      "Model: KNeighborsClassifier\n",
      "Train score: 0.8072454968629832\n",
      "Test Score: 0.8105504587155963\n",
      "\n",
      "[[3485  782]\n",
      " [  44   49]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.82      0.89      4267\n",
      "           1       0.06      0.53      0.11        93\n",
      "\n",
      "    accuracy                           0.81      4360\n",
      "   macro avg       0.52      0.67      0.50      4360\n",
      "weighted avg       0.97      0.81      0.88      4360\n",
      "\n",
      "Balanced Accuracy: 0.6718073940795957\n",
      "----------------------------------------------------------------\n",
      "Model: AdaBoostClassifier\n",
      "Train score: 0.8329892734264319\n",
      "Test Score: 0.8392201834862385\n",
      "\n",
      "[[3603  664]\n",
      " [  37   56]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.84      0.91      4267\n",
      "           1       0.08      0.60      0.14        93\n",
      "\n",
      "    accuracy                           0.84      4360\n",
      "   macro avg       0.53      0.72      0.52      4360\n",
      "weighted avg       0.97      0.84      0.89      4360\n",
      "\n",
      "Balanced Accuracy: 0.7232688474438741\n",
      "----------------------------------------------------------------\n",
      "Model: SVC\n",
      "Train score: 0.8381299332119004\n",
      "Test Score: 0.8426605504587156\n",
      "\n",
      "[[3619  648]\n",
      " [  38   55]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.85      0.91      4267\n",
      "           1       0.08      0.59      0.14        93\n",
      "\n",
      "    accuracy                           0.84      4360\n",
      "   macro avg       0.53      0.72      0.53      4360\n",
      "weighted avg       0.97      0.84      0.90      4360\n",
      "\n",
      "Balanced Accuracy: 0.7197673568849208\n",
      "----------------------------------------------------------------\n",
      "Model: RandomForestClassifier\n",
      "Train score: 0.8391013964784456\n",
      "Test Score: 0.8362385321100917\n",
      "\n",
      "[[3588  679]\n",
      " [  35   58]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.84      0.91      4267\n",
      "           1       0.08      0.62      0.14        93\n",
      "\n",
      "    accuracy                           0.84      4360\n",
      "   macro avg       0.53      0.73      0.52      4360\n",
      "weighted avg       0.97      0.84      0.89      4360\n",
      "\n",
      "Balanced Accuracy: 0.7322638604342906\n",
      "----------------------------------------------------------------\n",
      "Model: ExtraTreesClassifier\n",
      "Train score: 0.8336773932402348\n",
      "Test Score: 0.8245412844036697\n",
      "\n",
      "[[3546  721]\n",
      " [  44   49]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.83      0.90      4267\n",
      "           1       0.06      0.53      0.11        93\n",
      "\n",
      "    accuracy                           0.82      4360\n",
      "   macro avg       0.53      0.68      0.51      4360\n",
      "weighted avg       0.97      0.82      0.89      4360\n",
      "\n",
      "Balanced Accuracy: 0.6789552731515431\n",
      "----------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "#Test undersampled \n",
    "undersample = RandomUnderSampler(sampling_strategy=0.5)\n",
    "X_under, y_under = undersample.fit_resample(X_train_scaled, y_train)\n",
    "data = X_under, X_test_scaled, y_under, y_test\n",
    "test_model_under(LogisticRegression(), data)\n",
    "test_model_under(GaussianNB(), data)\n",
    "test_model_under(KNeighborsClassifier(), data)\n",
    "test_model_under(AdaBoostClassifier(), data)\n",
    "test_model_under(SVC(), data)\n",
    "test_model_under(RandomForestClassifier(), data)\n",
    "test_model_under(ExtraTreesClassifier(), data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "hLlbe188ftud",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "hLlbe188ftud",
    "outputId": "b2e894d4-7964-44ac-ccb8-586eb3060e33",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(29065, 10)\n",
      "(29065,)\n",
      "(51087, 10)\n",
      "(51087,)\n"
     ]
    }
   ],
   "source": [
    "print(X.shape)\n",
    "print(y.shape)\n",
    "print(X_smoteenn.shape)\n",
    "print(y_smoteenn.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "xUmhjlLmfQ3n",
   "metadata": {
    "id": "xUmhjlLmfQ3n"
   },
   "outputs": [],
   "source": [
    "def test_model2(model, data):\n",
    "    X_train, X_test, y_train, y_test = data\n",
    "    reg = model.fit(X_train, y_train)\n",
    "    \n",
    "    print(f'Model: {type(reg).__name__}')\n",
    "    print(f'Train score: {reg.score(X_train, y_train)}')\n",
    "    print(f'Test Score: {reg.score(X_test, y_test)}\\n')\n",
    "    y_pred = reg.predict(X_test)\n",
    "    y_true = y_test\n",
    "    print(confusion_matrix(y_true, y_pred))\n",
    "    print(classification_report(y_test, y_pred))\n",
    "    print(balanced_accuracy_score(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "id": "FOZ6FsXBffGc",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 885
    },
    "id": "FOZ6FsXBffGc",
    "outputId": "e93a6259-d189-4d2d-9488-e7c10ac6a664"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: RUSBoostClassifier\n",
      "Train score: 0.74802671523983\n",
      "Test Score: 0.75\n",
      "\n",
      "[[3198 1070]\n",
      " [  20   72]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.75      0.85      4268\n",
      "           1       0.06      0.78      0.12        92\n",
      "\n",
      "    accuracy                           0.75      4360\n",
      "   macro avg       0.53      0.77      0.49      4360\n",
      "weighted avg       0.97      0.75      0.84      4360\n",
      "\n",
      "0.7659528951550467\n",
      "Model: BalancedRandomForestClassifier\n",
      "Train score: 0.6667880995749849\n",
      "Test Score: 0.6630733944954128\n",
      "\n",
      "[[2814 1454]\n",
      " [  15   77]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.66      0.79      4268\n",
      "           1       0.05      0.84      0.09        92\n",
      "\n",
      "    accuracy                           0.66      4360\n",
      "   macro avg       0.52      0.75      0.44      4360\n",
      "weighted avg       0.97      0.66      0.78      4360\n",
      "\n",
      "0.7481408663053666\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "ignored",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-135-e3ee0a7371ef>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mtest_model2\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mRUSBoostClassifier\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mtest_model2\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mBalancedRandomForestClassifier\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmax_depth\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrandom_state\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m12\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0mtest_model2\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mBalancedBaggingClassifier\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-134-83ee2624691d>\u001b[0m in \u001b[0;36mtest_model2\u001b[0;34m(model, data)\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mtest_model2\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m     \u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_test\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m     \u001b[0mreg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf'Model: {type(reg).__name__}'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/imblearn/ensemble/_bagging.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y)\u001b[0m\n\u001b[1;32m    319\u001b[0m         \u001b[0;31m# RandomUnderSampler is not supporting sample_weight. We need to pass\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    320\u001b[0m         \u001b[0;31m# None.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 321\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_fit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmax_samples\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    322\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    323\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_more_tags\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/sklearn/ensemble/_bagging.py\u001b[0m in \u001b[0;36m_fit\u001b[0;34m(self, X, y, max_samples, max_depth, sample_weight)\u001b[0m\n\u001b[1;32m    335\u001b[0m             \u001b[0mmax_features\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmax_features\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    336\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmax_features\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfloat\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 337\u001b[0;31m             \u001b[0mmax_features\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmax_features\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mn_features_in_\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    338\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    339\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"max_features must be int or float\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'BalancedBaggingClassifier' object has no attribute 'n_features_in_'"
     ]
    }
   ],
   "source": [
    "data = X_train, X_test, y_train, y_test\n",
    "test_model2(RUSBoostClassifier(), data)\n",
    "test_model2(BalancedRandomForestClassifier(max_depth=2, random_state=12), data)\n",
    "test_model2(BalancedBaggingClassifier(), data)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "Madq5JLMMk9u",
   "metadata": {
    "id": "Madq5JLMMk9u"
   },
   "outputs": [],
   "source": [
    "# Use a combination of over and under sampling called SMOTEENN\n",
    "smote_enn = SMOTEENN(random_state=12)\n",
    "X_smoteenn, y_smoteenn = smote_enn.fit_resample(X, y)\n",
    "X_train_smot, X_test_smot, y_train_smot, y_test_smot = train_test_split(X_smoteenn, y_smoteenn, train_size=.85 , random_state=12)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "id": "hPOkjwbgacUH",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "hPOkjwbgacUH",
    "outputId": "016ea489-a8af-4d61-d91c-86d50cc5f012"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: LogisticRegression\n",
      "Train score: 0.8246781659489211\n",
      "Test Score: 0.7256880733944954\n",
      "\n",
      "[[3096 1172]\n",
      " [  24   68]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.73      0.84      4268\n",
      "           1       0.05      0.74      0.10        92\n",
      "\n",
      "    accuracy                           0.73      4360\n",
      "   macro avg       0.52      0.73      0.47      4360\n",
      "weighted avg       0.97      0.73      0.82      4360\n",
      "\n",
      "----------------------------------------------------------------\n",
      "                   pre       rec       spe        f1       geo       iba       sup\n",
      "\n",
      "          0       0.99      0.73      0.74      0.84      0.73      0.54      4268\n",
      "          1       0.05      0.74      0.73      0.10      0.73      0.54        92\n",
      "\n",
      "avg / total       0.97      0.73      0.74      0.82      0.73      0.54      4360\n",
      "\n",
      "Balanced Accuracy: 0.7322643739048939\n",
      "----------------------------------------------------------------\n",
      "Model: GaussianNB\n",
      "Train score: 0.8110678672592866\n",
      "Test Score: 0.710091743119266\n",
      "\n",
      "[[3026 1242]\n",
      " [  22   70]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.71      0.83      4268\n",
      "           1       0.05      0.76      0.10        92\n",
      "\n",
      "    accuracy                           0.71      4360\n",
      "   macro avg       0.52      0.73      0.46      4360\n",
      "weighted avg       0.97      0.71      0.81      4360\n",
      "\n",
      "----------------------------------------------------------------\n",
      "                   pre       rec       spe        f1       geo       iba       sup\n",
      "\n",
      "          0       0.99      0.71      0.76      0.83      0.73      0.54      4268\n",
      "          1       0.05      0.76      0.71      0.10      0.73      0.54        92\n",
      "\n",
      "avg / total       0.97      0.71      0.76      0.81      0.73      0.54      4360\n",
      "\n",
      "Balanced Accuracy: 0.7349333767980115\n",
      "----------------------------------------------------------------\n",
      "Model: KNeighborsClassifier\n",
      "Train score: 1.0\n",
      "Test Score: 0.8405963302752294\n",
      "\n",
      "[[3573  695]\n",
      " [   0   92]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.84      0.91      4268\n",
      "           1       0.12      1.00      0.21        92\n",
      "\n",
      "    accuracy                           0.84      4360\n",
      "   macro avg       0.56      0.92      0.56      4360\n",
      "weighted avg       0.98      0.84      0.90      4360\n",
      "\n",
      "----------------------------------------------------------------\n",
      "                   pre       rec       spe        f1       geo       iba       sup\n",
      "\n",
      "          0       1.00      0.84      1.00      0.91      0.91      0.82      4268\n",
      "          1       0.12      1.00      0.84      0.21      0.91      0.85        92\n",
      "\n",
      "avg / total       0.98      0.84      1.00      0.90      0.91      0.82      4360\n",
      "\n",
      "Balanced Accuracy: 0.9185801312089972\n",
      "----------------------------------------------------------------\n",
      "Model: AdaBoostClassifier\n",
      "Train score: 0.85275084632568\n",
      "Test Score: 0.736697247706422\n",
      "\n",
      "[[3154 1114]\n",
      " [  34   58]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.74      0.85      4268\n",
      "           1       0.05      0.63      0.09        92\n",
      "\n",
      "    accuracy                           0.74      4360\n",
      "   macro avg       0.52      0.68      0.47      4360\n",
      "weighted avg       0.97      0.74      0.83      4360\n",
      "\n",
      "----------------------------------------------------------------\n",
      "                   pre       rec       spe        f1       geo       iba       sup\n",
      "\n",
      "          0       0.99      0.74      0.63      0.85      0.68      0.47      4268\n",
      "          1       0.05      0.63      0.74      0.09      0.68      0.46        92\n",
      "\n",
      "avg / total       0.97      0.74      0.63      0.83      0.68      0.47      4360\n",
      "\n",
      "Balanced Accuracy: 0.6847112994580498\n",
      "----------------------------------------------------------------\n",
      "Model: SVC\n",
      "Train score: 0.8132556479285171\n",
      "Test Score: 0.6449541284403669\n",
      "\n",
      "[[2731 1537]\n",
      " [  11   81]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.64      0.78      4268\n",
      "           1       0.05      0.88      0.09        92\n",
      "\n",
      "    accuracy                           0.64      4360\n",
      "   macro avg       0.52      0.76      0.44      4360\n",
      "weighted avg       0.98      0.64      0.76      4360\n",
      "\n",
      "----------------------------------------------------------------\n",
      "                   pre       rec       spe        f1       geo       iba       sup\n",
      "\n",
      "          0       1.00      0.64      0.88      0.78      0.75      0.55      4268\n",
      "          1       0.05      0.88      0.64      0.09      0.75      0.58        92\n",
      "\n",
      "avg / total       0.98      0.64      0.88      0.76      0.75      0.55      4360\n",
      "\n",
      "Balanced Accuracy: 0.7601564728413674\n",
      "----------------------------------------------------------------\n",
      "Model: RandomForestClassifier\n",
      "Train score: 0.8545931879418741\n",
      "Test Score: 0.7211009174311926\n",
      "\n",
      "[[3073 1195]\n",
      " [  21   71]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.72      0.83      4268\n",
      "           1       0.06      0.77      0.10        92\n",
      "\n",
      "    accuracy                           0.72      4360\n",
      "   macro avg       0.52      0.75      0.47      4360\n",
      "weighted avg       0.97      0.72      0.82      4360\n",
      "\n",
      "----------------------------------------------------------------\n",
      "                   pre       rec       spe        f1       geo       iba       sup\n",
      "\n",
      "          0       0.99      0.72      0.77      0.83      0.75      0.55      4268\n",
      "          1       0.06      0.77      0.72      0.10      0.75      0.56        92\n",
      "\n",
      "avg / total       0.97      0.72      0.77      0.82      0.75      0.55      4360\n",
      "\n",
      "Balanced Accuracy: 0.7458742512530052\n",
      "----------------------------------------------------------------\n",
      "Model: ExtraTreesClassifier\n",
      "Train score: 0.8349952789996085\n",
      "Test Score: 0.6910550458715596\n",
      "\n",
      "[[2946 1322]\n",
      " [  25   67]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.69      0.81      4268\n",
      "           1       0.05      0.73      0.09        92\n",
      "\n",
      "    accuracy                           0.69      4360\n",
      "   macro avg       0.52      0.71      0.45      4360\n",
      "weighted avg       0.97      0.69      0.80      4360\n",
      "\n",
      "----------------------------------------------------------------\n",
      "                   pre       rec       spe        f1       geo       iba       sup\n",
      "\n",
      "          0       0.99      0.69      0.73      0.81      0.71      0.50      4268\n",
      "          1       0.05      0.73      0.69      0.09      0.71      0.50        92\n",
      "\n",
      "avg / total       0.97      0.69      0.73      0.80      0.71      0.50      4360\n",
      "\n",
      "Balanced Accuracy: 0.7092569577441832\n",
      "----------------------------------------------------------------\n",
      "Model: XGBClassifier\n",
      "Train score: 0.8823895170762038\n",
      "Test Score: 0.7412844036697248\n",
      "\n",
      "[[3161 1107]\n",
      " [  21   71]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.74      0.85      4268\n",
      "           1       0.06      0.77      0.11        92\n",
      "\n",
      "    accuracy                           0.74      4360\n",
      "   macro avg       0.53      0.76      0.48      4360\n",
      "weighted avg       0.97      0.74      0.83      4360\n",
      "\n",
      "----------------------------------------------------------------\n",
      "                   pre       rec       spe        f1       geo       iba       sup\n",
      "\n",
      "          0       0.99      0.74      0.77      0.85      0.76      0.57      4268\n",
      "          1       0.06      0.77      0.74      0.11      0.76      0.57        92\n",
      "\n",
      "avg / total       0.97      0.74      0.77      0.83      0.76      0.57      4360\n",
      "\n",
      "Balanced Accuracy: 0.7561835296035206\n",
      "----------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "# Test the SMOTEENN sampled models\n",
    "data = X_train_smot, X_test, y_train_smot, y_test\n",
    "test_model_smot(LogisticRegression(max_iter=100000), data)\n",
    "test_model_smot(GaussianNB(), data)\n",
    "test_model_smot(KNeighborsClassifier(n_neighbors=7, weights='distance'), data)\n",
    "test_model_smot(AdaBoostClassifier(), data)\n",
    "test_model_smot(SVC(), data)\n",
    "test_model_smot(RandomForestClassifier(max_depth=6, random_state=0), data)\n",
    "test_model_smot(ExtraTreesClassifier(max_depth=6, random_state=0), data)\n",
    "test_model_smot(XGBClassifier(objective='binary:logistic',n_estimators=10000,max_depth=6, learning_rate=.0001, n_jobs=-1), data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "bcliEj-2oVjC",
   "metadata": {
    "id": "bcliEj-2oVjC"
   },
   "outputs": [],
   "source": [
    "# KNeighborsClassifier is a clear winner!\n",
    "knn = KNeighborsClassifier(n_neighbors=3, weights='distance')\n",
    "model = knn.fit(X_train_smot, y_train_smot)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "17a3eda3",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'X_train_scaled' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-12-b6483f2cdc41>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mlr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mLogisticRegression\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mlr_model\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mclf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train_scaled\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train_scaled\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'X_train_scaled' is not defined"
     ]
    }
   ],
   "source": [
    "lr = LogisticRegression()\n",
    "lr_model = clf.fit(X_train_scaled, y_train_scaled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "TRhPtNTXoqxJ",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "TRhPtNTXoqxJ",
    "outputId": "7143897e-136f-4b86-cab4-e2673d12ccf4"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[3621  670]\n",
      " [   0   69]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.84      0.92      4291\n",
      "           1       0.09      1.00      0.17        69\n",
      "\n",
      "    accuracy                           0.85      4360\n",
      "   macro avg       0.55      0.92      0.54      4360\n",
      "weighted avg       0.99      0.85      0.90      4360\n",
      "\n",
      "Balanced accuracy score: 0.9219296201351665\n",
      "                   pre       rec       spe        f1       geo       iba       sup\n",
      "\n",
      "          0       1.00      0.84      1.00      0.92      0.92      0.83      4291\n",
      "          1       0.09      1.00      0.84      0.17      0.92      0.86        69\n",
      "\n",
      "avg / total       0.99      0.85      1.00      0.90      0.92      0.83      4360\n",
      "\n"
     ]
    }
   ],
   "source": [
    "y_pred = model.predict(X_test)\n",
    "y_true = y_test\n",
    "# print(f'Train score: {xgc.score(X, y)}')\n",
    "# print(f'Test Score: {xgc.score(X_test_smot, y_test_smot)}\\n')\n",
    "print(confusion_matrix(y_true, y_pred))\n",
    "\n",
    "print(classification_report(y_true, y_pred))\n",
    "print(f'Balanced accuracy score: {balanced_accuracy_score(y_true, y_pred)}')\n",
    "print(classification_report_imbalanced(y_true, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "E8KG8-qmOjqD",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 607
    },
    "id": "E8KG8-qmOjqD",
    "outputId": "a6776b41-76f8-4dbf-b088-82942b0bdbd4"
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 360x720 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "from matplotlib import pyplot as plt\n",
    "features = sorted(zip(X.columns, lr_model.feature_importances_), key = lambda x: x[1])\n",
    "cols = [f[0] for f in features]\n",
    "width = [f[1] for f in features]\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "\n",
    "fig.set_size_inches(5,10)\n",
    "plt.margins(y=0.001)\n",
    "\n",
    "\n",
    "ax.barh(y=cols, width=width)\n",
    "plt.title('Most Predictive Features')\n",
    "# plt.savefig('top_features.png')\n",
    "\n",
    "plt.show()\n",
    "# plt.savefig('Visualizations/balanced_most_pred.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "V3msvtWoPk9S",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "V3msvtWoPk9S",
    "outputId": "e7f8f15c-b214-4e5b-e749-1d4df6a3cbc7"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_2\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_6 (Dense)             (None, 16)                176       \n",
      "                                                                 \n",
      " dense_7 (Dense)             (None, 8)                 136       \n",
      "                                                                 \n",
      " dense_8 (Dense)             (None, 1)                 9         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 321\n",
      "Trainable params: 321\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "nn_model = tf.keras.models.Sequential()\n",
    "\n",
    "# First hidden layer\n",
    "nn_model.add(tf.keras.layers.Dense(units=16, activation=\"sigmoid\", input_dim=10))\n",
    "# Second hidden layer\n",
    "nn_model.add(tf.keras.layers.Dense(units=8, activation=\"sigmoid\"))\n",
    "\n",
    "# Output layer\n",
    "nn_model.add(tf.keras.layers.Dense(units=1, activation=\"sigmoid\"))\n",
    "\n",
    "# Check the structure of the model\n",
    "nn_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "BCUAtnKdPoEQ",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "BCUAtnKdPoEQ",
    "outputId": "88608fb3-0d55-478b-c2e7-b8f73be4fcff"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "41/41 [==============================] - 1s 2ms/step - loss: 0.6367 - accuracy: 0.6667\n",
      "Epoch 2/20\n",
      "41/41 [==============================] - 0s 2ms/step - loss: 0.6257 - accuracy: 0.6667\n",
      "Epoch 3/20\n",
      "41/41 [==============================] - 0s 2ms/step - loss: 0.6170 - accuracy: 0.6667\n",
      "Epoch 4/20\n",
      "41/41 [==============================] - 0s 2ms/step - loss: 0.6062 - accuracy: 0.6667\n",
      "Epoch 5/20\n",
      "41/41 [==============================] - 0s 2ms/step - loss: 0.5940 - accuracy: 0.6667\n",
      "Epoch 6/20\n",
      "41/41 [==============================] - 0s 2ms/step - loss: 0.5805 - accuracy: 0.6667\n",
      "Epoch 7/20\n",
      "41/41 [==============================] - 0s 2ms/step - loss: 0.5659 - accuracy: 0.6682\n",
      "Epoch 8/20\n",
      "41/41 [==============================] - 0s 2ms/step - loss: 0.5511 - accuracy: 0.6883\n",
      "Epoch 9/20\n",
      "41/41 [==============================] - 0s 2ms/step - loss: 0.5373 - accuracy: 0.7162\n",
      "Epoch 10/20\n",
      "41/41 [==============================] - 0s 2ms/step - loss: 0.5247 - accuracy: 0.7293\n",
      "Epoch 11/20\n",
      "41/41 [==============================] - 0s 2ms/step - loss: 0.5138 - accuracy: 0.7347\n",
      "Epoch 12/20\n",
      "41/41 [==============================] - 0s 2ms/step - loss: 0.5048 - accuracy: 0.7432\n",
      "Epoch 13/20\n",
      "41/41 [==============================] - 0s 2ms/step - loss: 0.4969 - accuracy: 0.7471\n",
      "Epoch 14/20\n",
      "41/41 [==============================] - 0s 2ms/step - loss: 0.4903 - accuracy: 0.7587\n",
      "Epoch 15/20\n",
      "41/41 [==============================] - 0s 2ms/step - loss: 0.4849 - accuracy: 0.7657\n",
      "Epoch 16/20\n",
      "41/41 [==============================] - 0s 2ms/step - loss: 0.4803 - accuracy: 0.7680\n",
      "Epoch 17/20\n",
      "41/41 [==============================] - 0s 2ms/step - loss: 0.4761 - accuracy: 0.7742\n",
      "Epoch 18/20\n",
      "41/41 [==============================] - 0s 2ms/step - loss: 0.4727 - accuracy: 0.7780\n",
      "Epoch 19/20\n",
      "41/41 [==============================] - 0s 2ms/step - loss: 0.4698 - accuracy: 0.7773\n",
      "Epoch 20/20\n",
      "41/41 [==============================] - 0s 2ms/step - loss: 0.4672 - accuracy: 0.7773\n"
     ]
    }
   ],
   "source": [
    "nn_model.compile(loss=\"binary_crossentropy\", optimizer=\"adam\", metrics=[\"accuracy\"])\n",
    "fit_model = nn_model.fit(X_under, y_under, epochs=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "iMCAB1pbP847",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "iMCAB1pbP847",
    "outputId": "7fd77ad4-f28b-4f53-d0d7-54c56788c5b0"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "182/182 - 0s - loss: 0.3319 - accuracy: 0.8366 - 336ms/epoch - 2ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.33186104893684387, 0.8365731835365295]"
      ]
     },
     "execution_count": 210,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nn_model.evaluate(X_test_scaled,y_test,verbose=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "pOvLmseISCrr",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "pOvLmseISCrr",
    "outputId": "929e483e-7939-4bd5-fdb9-3a9c0b0abb32"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Accuracy: 0.837\n"
     ]
    }
   ],
   "source": [
    "loss, acc = nn_model.evaluate(X_test_scaled, y_test, verbose=0)\n",
    "print('Test Accuracy: %.3f' % acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "C24NogsbS5ib",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 282
    },
    "id": "C24NogsbS5ib",
    "outputId": "a2f7fbb8-afd8-4f01-c6d0-cc3dbcb8f29d"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.collections.PathCollection at 0x7fec3fa9d310>"
      ]
     },
     "execution_count": 219,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.scatter(nn_model.predict(X_test), y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "mzQcIqiUQY6I",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 392
    },
    "id": "mzQcIqiUQY6I",
    "outputId": "2ee8f2f7-7fef-4550-dd23-29aff06de94c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train score: 0.8256063994495098\n",
      "Test Score: 0.8274557027352486\n",
      "\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "ignored",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-216-c864a8b46c3d>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;31m# print(confusion_matrix(y_test, y_pred))\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;31m#print(classification_report_imbalanced(y_test, y_pred))\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m \u001b[0mbalanced_accuracy_score\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_pred\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py\u001b[0m in \u001b[0;36mbalanced_accuracy_score\u001b[0;34m(y_true, y_pred, sample_weight, adjusted)\u001b[0m\n\u001b[1;32m   1947\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1948\u001b[0m     \"\"\"\n\u001b[0;32m-> 1949\u001b[0;31m     \u001b[0mC\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mconfusion_matrix\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_true\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_pred\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msample_weight\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1950\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0merrstate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdivide\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"ignore\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minvalid\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"ignore\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1951\u001b[0m         \u001b[0mper_class\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdiag\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mC\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0mC\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py\u001b[0m in \u001b[0;36mconfusion_matrix\u001b[0;34m(y_true, y_pred, labels, sample_weight, normalize)\u001b[0m\n\u001b[1;32m    300\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    301\u001b[0m     \"\"\"\n\u001b[0;32m--> 302\u001b[0;31m     \u001b[0my_type\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_true\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_pred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_check_targets\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_true\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_pred\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    303\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0my_type\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;34m\"binary\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"multiclass\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    304\u001b[0m         \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"%s is not supported\"\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0my_type\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py\u001b[0m in \u001b[0;36m_check_targets\u001b[0;34m(y_true, y_pred)\u001b[0m\n\u001b[1;32m     93\u001b[0m         raise ValueError(\n\u001b[1;32m     94\u001b[0m             \"Classification metrics can't handle a mix of {0} and {1} targets\".format(\n\u001b[0;32m---> 95\u001b[0;31m                 \u001b[0mtype_true\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtype_pred\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     96\u001b[0m             )\n\u001b[1;32m     97\u001b[0m         )\n",
      "\u001b[0;31mValueError\u001b[0m: Classification metrics can't handle a mix of binary and continuous targets"
     ]
    }
   ],
   "source": [
    "y_pred = nn_model.predict(X_test_scaled)\n",
    "print(f'Train score: {xgc.score(X_train_scaled, y_train)}')\n",
    "print(f'Test Score: {xgc.score(X_test_scaled, y_test)}\\n')\n",
    "# print(confusion_matrix(y_test, y_pred))\n",
    "#print(classification_report_imbalanced(y_test, y_pred))\n",
    "balanced_accuracy_score(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9tniNdv7TuXN",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 419
    },
    "id": "9tniNdv7TuXN",
    "outputId": "9bdb66fa-09a1-4585-ebfb-9a8e5f5d5ace"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>gender</th>\n",
       "      <th>age</th>\n",
       "      <th>hypertension</th>\n",
       "      <th>heart_disease</th>\n",
       "      <th>ever_married</th>\n",
       "      <th>work_type</th>\n",
       "      <th>residence_type</th>\n",
       "      <th>avg_glucose_level</th>\n",
       "      <th>bmi</th>\n",
       "      <th>smoking_status</th>\n",
       "      <th>stroke</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>26.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>78.05</td>\n",
       "      <td>30.8</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>71.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>108.70</td>\n",
       "      <td>31.2</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>46.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>201.42</td>\n",
       "      <td>50.8</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>52.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>124.27</td>\n",
       "      <td>22.2</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>67.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>95.48</td>\n",
       "      <td>30.1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29060</th>\n",
       "      <td>0</td>\n",
       "      <td>51.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>226.04</td>\n",
       "      <td>27.1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29061</th>\n",
       "      <td>0</td>\n",
       "      <td>60.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>71.98</td>\n",
       "      <td>33.4</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29062</th>\n",
       "      <td>0</td>\n",
       "      <td>45.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>77.45</td>\n",
       "      <td>42.2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29063</th>\n",
       "      <td>1</td>\n",
       "      <td>21.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>88.31</td>\n",
       "      <td>46.6</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29064</th>\n",
       "      <td>0</td>\n",
       "      <td>75.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>56.23</td>\n",
       "      <td>25.3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>29065 rows Ã— 11 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       gender   age  hypertension  ...   bmi  smoking_status  stroke\n",
       "0           0  26.0             0  ...  30.8               1       0\n",
       "1           1  71.0             1  ...  31.2               2       0\n",
       "2           0  46.0             0  ...  50.8               2       0\n",
       "3           0  52.0             0  ...  22.2               2       0\n",
       "4           1  67.0             0  ...  30.1               0       0\n",
       "...       ...   ...           ...  ...   ...             ...     ...\n",
       "29060       0  51.0             0  ...  27.1               1       0\n",
       "29061       0  60.0             0  ...  33.4               1       0\n",
       "29062       0  45.0             0  ...  42.2               0       0\n",
       "29063       1  21.0             0  ...  46.6               1       0\n",
       "29064       0  75.0             0  ...  25.3               1       0\n",
       "\n",
       "[29065 rows x 11 columns]"
      ]
     },
     "execution_count": 220,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "Nr-GRT6GRELg",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Nr-GRT6GRELg",
    "outputId": "2d35a77a-a9fb-4d36-fa28-061b69c0567d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted: 0.744\n"
     ]
    }
   ],
   "source": [
    "row = [1, 13, 1, 1, 1, 2, 1, 213, 23, 1]\n",
    "yhat = nn_model.predict([row])\n",
    "print('Predicted: %.3f' % yhat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "z7fxDFc2Q7ZF",
   "metadata": {
    "id": "z7fxDFc2Q7ZF"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "name": "model_testing.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
